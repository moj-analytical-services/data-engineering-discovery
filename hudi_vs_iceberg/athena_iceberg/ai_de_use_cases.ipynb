{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athena Iceberg - Data Eng Use Cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pydbtools as pydb\n",
    "import py_aws_vault_auth\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = \"athena_iceberg\"\n",
    "region = \"eu-west-1\"\n",
    "bucketname = \"sb-test-bucket-ireland\"\n",
    "db_name = \"wto_hudi_iceberg\"\n",
    "s3_root_folder = \"wo/de_use_cases\"\n",
    "s3_base_path = f\"s3://{bucketname}/{s3_root_folder}/{comparison}\"\n",
    "db_base_path = f\"{s3_base_path}database/\"\n",
    "\n",
    "environ_auth = py_aws_vault_auth.authenticate(\"sso-sandbox\", prompt=\"python\", return_as=\"environ\")\n",
    "os.environ.update(environ_auth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk insert and add curation columns "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up variables for bulk insert test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "senario = \"bulk_insert\"\n",
    "source_fl = f\"s3://sb-test-bucket-ireland/dummy_data/full_load/\"\n",
    "source_ud = f\"s3://sb-test-bucket-ireland/dummy_data/updates/\"\n",
    "temp_table_name = f\"{comparison}_{senario}_temp\"\n",
    "dest_table_name = f\"{comparison}_{senario}_iceberg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary table from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table_sql_1 = f\"\"\"\n",
    "    CREATE EXTERNAL TABLE IF NOT EXISTS {db_name}.{temp_table_name} (\n",
    "        product_id string,\n",
    "        product_name string,\n",
    "        price int,\n",
    "        extraction_timestamp timestamp,\n",
    "        op string\n",
    "    )\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '{source_fl}'\n",
    "\"\"\"\n",
    "#wr.athena.read_sql_query(sql=temp_table_sql, database=db_name, ctas_approach=False)\n",
    "# wr.athena.read_sql_query(f\"DROP TABLE {temp_table_name}\", database=db_name, ctas_approach=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the table is populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.athena.read_sql_query(f\"SELECT * FROM {temp_table_name}\", database=db_name, ctas_approach=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an iceberg table from source table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_table_sql = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {db_name}.{dest_table_name}\n",
    "        WITH (table_type='ICEBERG',\n",
    "        location='{db_base_path}{senario}/',\n",
    "        format='PARQUET',\n",
    "        is_external=false)\n",
    "        AS SELECT\n",
    "            product_id,\n",
    "            product_name,\n",
    "            price,\n",
    "            CAST(extraction_timestamp AS timestamp(6)) AS extraction_timestamp,\n",
    "            op \n",
    "           FROM {db_name}.{temp_table_name};\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=dest_table_sql, database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "##wr.athena.delete_table(database=db_name, table=temp_table_name)\n",
    "\n",
    "## 13 sec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update destination iceberg table with new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_columns_sql = f\"\"\"\n",
    "    ALTER TABLE {db_name}.{dest_table_name}\n",
    "    ADD COLUMNS (start_datetime TIMESTAMP, end_datetime TIMESTAMP, is_current BOOLEAN)\n",
    "\"\"\"\n",
    "update_values_sql = f\"\"\"\n",
    "    UPDATE {db_name}.{dest_table_name}\n",
    "    SET start_datetime = extraction_timestamp, \n",
    "        end_datetime = CAST(TIMESTAMP '2250-01-01' as TIMESTAMP(6)), \n",
    "        is_current = true\n",
    "\"\"\"\n",
    "#wr.athena.read_sql_query(sql=update_values_sql, database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "print(\"Updated values\")\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False, workgroup='Athena3')\n",
    "##wr.athena.delete_table(database=db_name, table=temp_table_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete and recreate tempory table from update file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.athena.read_sql_query(f\"DROP TABLE IF EXISTS {temp_table_name}\", database=db_name, ctas_approach=False)\n",
    "temp_table_sql = f\"\"\"\n",
    "    CREATE EXTERNAL TABLE {db_name}.{temp_table_name} (\n",
    "        product_id string,\n",
    "        product_name string,\n",
    "        price int,\n",
    "        extraction_timestamp timestamp,\n",
    "        op string\n",
    "    )\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '{source_ud}'\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=temp_table_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {temp_table_name}\", database=db_name, ctas_approach=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update destination table when key is source (CDC / update) table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dest_sql = f\"\"\"\n",
    "    MERGE INTO {db_name}.{dest_table_name} dest\n",
    "        USING {db_name}.{temp_table_name} sour\n",
    "            ON sour.product_id = dest.product_id\n",
    "    WHEN MATCHED AND dest.is_current = TRUE AND sour.extraction_timestamp > dest.extraction_timestamp\n",
    "        THEN UPDATE\n",
    "            SET end_datetime = sour.extraction_timestamp, is_current = FALSE;\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=update_dest_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert all updates from source table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_dest_sql = f\"\"\"\n",
    "INSERT INTO {db_name}.{dest_table_name}\n",
    "    SELECT product_id, product_name, price, CAST(extraction_timestamp AS TIMESTAMP(6)), op, \n",
    "      CAST(extraction_timestamp AS TIMESTAMP(6)), CAST(TIMESTAMP '2250-01-01' as TIMESTAMP(6)),TRUE\n",
    "    FROM {db_name}.{temp_table_name}\n",
    "\"\"\"\n",
    "wr.athena.read_sql_query(sql=update_dest_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.athena.read_sql_query(sql=temp_table_sql, database=db_name, ctas_approach=False)\n",
    "wr.athena.read_sql_query(f\"DROP TABLE {temp_table_name}\", database=db_name, ctas_approach=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of changes\n",
    "\n",
    "**SETUP**\n",
    "1. Create a temp table from FL\n",
    "2. Create iceberg full load via CTAS, adding mojap fields\n",
    "3. Create CDC temp table \n",
    "4. Create a CDC view adding mojap fields (didnt actualy do this last light as plain insert was quick enough for Sou's critera)\n",
    "\n",
    "**PROCESSING**\n",
    "1. Use merge to close is_current records in iceberg that exist in CDC (there is an issue of closing date flif multiple CDC)\n",
    "2. Insert CDC into iceberg\n",
    "\n",
    "**NEXT STEPS**\n",
    "1. Run processing as a single step\n",
    "2. Update the cdc insrt to a view\n",
    "3. Close multiple CDC updates with previous date\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSO Variables. Run below in terminal:\n",
    "\n",
    "```\n",
    "# pip3 install python-dotenv\n",
    "aws-vault exec sso-sandbox\n",
    "source /Users/william.orr/Developer/Projects/hudi-vs-iceberg/venv/bin/activate\n",
    "env | grep AWS > .env\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import athena_functions as af\n",
    "import awswrangler as wr\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from importlib import reload\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_directory = (\n",
    "    \"s3://sb-test-bucket-ireland/data-engineering-use-cases/dummy-data/\"\n",
    ")\n",
    "## Assumptions about real setup\n",
    "## data-engineering-use-cases/realistic-data/<column_count>_<row_count>/<test_type>/<name>00<x>.parquet\n",
    "## .../realistic-data/10_10K/full_load/\n",
    "## .../realistic-data/10_100M/updates/\n",
    "## .../realistic-data/100_10B/late_updates/\n",
    "\n",
    "full_load_filepath = f\"{input_data_directory}full_load/full_load.parquet\"\n",
    "updates_filepath = f\"{input_data_directory}updates/updates.parquet\"\n",
    "late_updates_filepath = f\"{input_data_directory}late_updates/late_updates.parquet\"\n",
    "output_data_directory = (\n",
    "    \"s3://sb-test-bucket-ireland/wo/de-usecases/athena/\"\n",
    ")\n",
    "\n",
    "db_name = \"wto_hudi_iceberg\"\n",
    "real_test_cases = [\"10_1K\", \"10_1M\", \"10_1B\", \"10_10B\", \"100_1K\", \"100_1M\", \"100_1B\", \"100_10B\"]\n",
    "current_test = full_load_filepath.split(\"/\")[-3].replace(\"-\", \"_\")\n",
    "dest_table_name = f\"ICE_{current_test}\"\n",
    "future_end_datetime = datetime.datetime(2250, 1, 1)\n",
    "primary_key = \"product_id\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Athena Specific Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create source full load & update tables\n",
    "(This will be done in glue for realistic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table full_load in wto_hudi_iceberg database with query ID 089b03c1-1f44-4859-ad30-1582bf1183f3\n",
      "\n",
      "Creating table updates in wto_hudi_iceberg database with query ID 20e889f7-95cc-4400-8fe4-84f266f93759\n",
      "\n",
      "Creating table late_updates in wto_hudi_iceberg database with query ID 09df0458-ad31-4c56-9933-4ec80a271a16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create source table name in format <test>_full_load, <test>_updates\n",
    "for table in [\"full_load\", \"updates\", \"late_updates\"]:\n",
    "    \n",
    "    source_folder = f\"{input_data_directory}{table}/\"\n",
    "    create_table_query = f\"\"\"\n",
    "        CREATE EXTERNAL TABLE IF NOT EXISTS {db_name}.dummy_data_{table} (\n",
    "        product_id string,\n",
    "        product_name string,\n",
    "        price int,\n",
    "        extraction_timestamp TIMESTAMP,\n",
    "        op string\n",
    "    )\n",
    "    STORED AS PARQUET\n",
    "    LOCATION '{source_folder}'\n",
    "    \"\"\"\n",
    "    query_id = wr.athena.start_query_execution(\n",
    "            sql=create_table_query, database=db_name, workgroup='Athena3') #, workgroup='Athena3'\n",
    "    print(f\"Creating table {table} in {db_name} database with query ID {query_id}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Bulk Insert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate SQL for live data in Glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        **DROP DEST TABLE** \n",
      "    \n",
      "    DROP TABLE IF EXISTS wto_hudi_iceberg.ICE_dummy_data;\n",
      "\n",
      "        **CREATE DEST TABLE** \n",
      "    \n",
      "    CREATE TABLE IF NOT EXISTS wto_hudi_iceberg.ICE_dummy_data\n",
      "        WITH (table_type='ICEBERG',\n",
      "        location='s3://sb-test-bucket-ireland/wo/de-usecases/athena/database/ICE_dummy_data',\n",
      "        format='PARQUET',\n",
      "        is_external=false)\n",
      "        AS SELECT\n",
      "            src.product_id, src.product_name, src.price, \n",
      "            CAST(extraction_timestamp AS TIMESTAMP(6)) AS extraction_timestamp, src.op,\n",
      "            CAST(extraction_timestamp AS TIMESTAMP(6)) AS start_datetime,\n",
      "            CAST(TIMESTAMP '2250-01-01 00:00:00' AS TIMESTAMP(6)) AS end_datetime,\n",
      "            CAST(true AS boolean) AS is_current\n",
      "           FROM wto_hudi_iceberg.dummy_data_full_load src;\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "bulk_insert_filepath = af.bulk_insert(\n",
    "    full_load_filepath, output_data_directory, future_end_datetime, demo=\"print_sql\")\n",
    "print(bulk_insert_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo data insert data to iceberg table (drop existing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed DROP in 1710 milliseconds,  0 bytes scanned\n",
      "completed INSERT in 2992 milliseconds,  490 bytes scanned\n",
      "total MB scanned: 0.0004673004150390625 in 4.702 seconds, ~ Cost =  $2.228262019343674e-09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>extraction_timestamp</th>\n",
       "      <th>op</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>is_current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>Heater</td>\n",
       "      <td>250</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2250-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>Thermostat</td>\n",
       "      <td>400</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2250-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003</td>\n",
       "      <td>Television</td>\n",
       "      <td>600</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2250-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004</td>\n",
       "      <td>Blender</td>\n",
       "      <td>100</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2250-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005</td>\n",
       "      <td>USB charger</td>\n",
       "      <td>50</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2250-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_name  price extraction_timestamp    op  \\\n",
       "0      00001       Heater    250  2022-01-01 01:01:01  <NA>   \n",
       "1      00002   Thermostat    400  2022-01-01 01:01:01  <NA>   \n",
       "2      00003   Television    600  2022-01-01 01:01:01  <NA>   \n",
       "3      00004      Blender    100  2022-01-01 01:01:01  <NA>   \n",
       "4      00005  USB charger     50  2022-01-01 01:01:01  <NA>   \n",
       "\n",
       "       start_datetime end_datetime  is_current  \n",
       "0 2022-01-01 01:01:01   2250-01-01        True  \n",
       "1 2022-01-01 01:01:01   2250-01-01        True  \n",
       "2 2022-01-01 01:01:01   2250-01-01        True  \n",
       "3 2022-01-01 01:01:01   2250-01-01        True  \n",
       "4 2022-01-01 01:01:01   2250-01-01        True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulk_insert_filepath = af.bulk_insert(\n",
    "    full_load_filepath, output_data_directory, future_end_datetime, demo=\"demo\")\n",
    "\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name}\", database=db_name, ctas_approach=False, workgroup='Athena3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintainence Scripts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'athena_functions' from '/Users/william.orr/Developer/Projects/hudi-vs-iceberg/hudi_vs_iceberg/athena_iceberg/athena_functions.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(af)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop destination ICE table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.athena.read_sql_query(f\"DROP TABLE IF EXISTS {dest_table_name}\", database=db_name, ctas_approach=False, workgroup='Athena3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing complex merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestException",
     "evalue": "An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 7:20: mismatched input '.'. Expecting: '='",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 37\u001b[0m\n\u001b[1;32m     24\u001b[0m sql2_5 \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m SELECT ice.*, tmp.*\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39m    FROM wto_hudi_iceberg.ICE_dummy_data ice\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[39m    JOIN wto_hudi_iceberg.ICE_dummy_data_temp tmp\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39m    ON (tmp.product_id = ice.product_id\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[39m    AND tmp.extraction_timestamp = ice.extraction_timestamp)\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     29\u001b[0m sql3 \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mMERGE INTO wto_hudi_iceberg.ICE_dummy_data ice\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[39m    USING wto_hudi_iceberg.ICE_dummy_data_temp tmp\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[39m    ON (tmp.product_id = ice.product_id\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m            SET ice.end_datetime = tmp.end_datetime_lead,\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[39m                ice.is_current = tmp.is_current\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m resp \u001b[39m=\u001b[39m wr\u001b[39m.\u001b[39;49mathena\u001b[39m.\u001b[39;49mstart_query_execution(\n\u001b[1;32m     38\u001b[0m     sql\u001b[39m=\u001b[39;49msql3, database\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwto_hudi_iceberg\u001b[39;49m\u001b[39m\"\u001b[39;49m, workgroup\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAthena3\u001b[39;49m\u001b[39m'\u001b[39;49m, wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m resp\n",
      "File \u001b[0;32m~/Developer/Projects/hudi-vs-iceberg/venv/lib/python3.9/site-packages/awswrangler/_config.py:542\u001b[0m, in \u001b[0;36mapply_configs.<locals>.wrapper\u001b[0;34m(*args_raw, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[39mdel\u001b[39;00m args[name]\n\u001b[1;32m    541\u001b[0m         args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords}\n\u001b[0;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/Developer/Projects/hudi-vs-iceberg/venv/lib/python3.9/site-packages/awswrangler/athena/_utils.py:482\u001b[0m, in \u001b[0;36mstart_query_execution\u001b[0;34m(sql, database, s3_output, workgroup, encryption, kms_key, params, boto3_session, max_cache_seconds, max_cache_query_inspections, max_remote_cache_entries, max_local_cache_entries, athena_query_wait_polling_delay, data_source, wait)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     wg_config: _WorkGroupConfig \u001b[39m=\u001b[39m _get_workgroup_config(session\u001b[39m=\u001b[39mboto3_session, workgroup\u001b[39m=\u001b[39mworkgroup)\n\u001b[0;32m--> 482\u001b[0m     query_execution_id \u001b[39m=\u001b[39m _start_query_execution(\n\u001b[1;32m    483\u001b[0m         sql\u001b[39m=\u001b[39;49msql,\n\u001b[1;32m    484\u001b[0m         wg_config\u001b[39m=\u001b[39;49mwg_config,\n\u001b[1;32m    485\u001b[0m         database\u001b[39m=\u001b[39;49mdatabase,\n\u001b[1;32m    486\u001b[0m         data_source\u001b[39m=\u001b[39;49mdata_source,\n\u001b[1;32m    487\u001b[0m         s3_output\u001b[39m=\u001b[39;49ms3_output,\n\u001b[1;32m    488\u001b[0m         workgroup\u001b[39m=\u001b[39;49mworkgroup,\n\u001b[1;32m    489\u001b[0m         encryption\u001b[39m=\u001b[39;49mencryption,\n\u001b[1;32m    490\u001b[0m         kms_key\u001b[39m=\u001b[39;49mkms_key,\n\u001b[1;32m    491\u001b[0m         boto3_session\u001b[39m=\u001b[39;49mboto3_session,\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    494\u001b[0m     \u001b[39mreturn\u001b[39;00m wait_query(\n\u001b[1;32m    495\u001b[0m         query_execution_id\u001b[39m=\u001b[39mquery_execution_id,\n\u001b[1;32m    496\u001b[0m         boto3_session\u001b[39m=\u001b[39mboto3_session,\n\u001b[1;32m    497\u001b[0m         athena_query_wait_polling_delay\u001b[39m=\u001b[39mathena_query_wait_polling_delay,\n\u001b[1;32m    498\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/Projects/hudi-vs-iceberg/venv/lib/python3.9/site-packages/awswrangler/athena/_utils.py:100\u001b[0m, in \u001b[0;36m_start_query_execution\u001b[0;34m(sql, wg_config, database, data_source, s3_output, workgroup, encryption, kms_key, boto3_session)\u001b[0m\n\u001b[1;32m     98\u001b[0m client_athena: boto3\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mclient(service_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mathena\u001b[39m\u001b[39m\"\u001b[39m, session\u001b[39m=\u001b[39mboto3_session)\n\u001b[1;32m     99\u001b[0m _logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39margs: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, pprint\u001b[39m.\u001b[39mpformat(args))\n\u001b[0;32m--> 100\u001b[0m response: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39;49mtry_it(\n\u001b[1;32m    101\u001b[0m     f\u001b[39m=\u001b[39;49mclient_athena\u001b[39m.\u001b[39;49mstart_query_execution,\n\u001b[1;32m    102\u001b[0m     ex\u001b[39m=\u001b[39;49mbotocore\u001b[39m.\u001b[39;49mexceptions\u001b[39m.\u001b[39;49mClientError,\n\u001b[1;32m    103\u001b[0m     ex_code\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mThrottlingException\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    104\u001b[0m     max_num_tries\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m    105\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m cast(\u001b[39mstr\u001b[39m, response[\u001b[39m\"\u001b[39m\u001b[39mQueryExecutionId\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Developer/Projects/hudi-vs-iceberg/venv/lib/python3.9/site-packages/awswrangler/_utils.py:334\u001b[0m, in \u001b[0;36mtry_it\u001b[0;34m(f, ex, ex_code, base, max_num_tries, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_num_tries):\n\u001b[1;32m    333\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    335\u001b[0m     \u001b[39mexcept\u001b[39;00m ex \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    336\u001b[0m         \u001b[39mif\u001b[39;00m ex_code \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(exception, \u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Developer/Projects/hudi-vs-iceberg/venv/lib/python3.9/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/Developer/Projects/hudi-vs-iceberg/venv/lib/python3.9/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mInvalidRequestException\u001b[0m: An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 7:20: mismatched input '.'. Expecting: '='"
     ]
    }
   ],
   "source": [
    "### TESTING\n",
    "sql1 = \"\"\"INSERT INTO wto_hudi_iceberg.ICE_dummy_data\n",
    "        SELECT src.product_id, src.product_name, src.price, \n",
    "            CAST(src.extraction_timestamp AS TIMESTAMP(6)) AS extraction_timestamp, src.op,\n",
    "            CAST(src.extraction_timestamp AS TIMESTAMP(6)), NULL, NULL\n",
    "        FROM wto_hudi_iceberg.dummy_data_late_updates src\"\"\"\n",
    "sql4 = \"DROP TABLE IF EXISTS wto_hudi_iceberg.ICE_dummy_data_temp\"\n",
    "sql2 = \"\"\"    CREATE TABLE IF NOT EXISTS wto_hudi_iceberg.ICE_dummy_data_temp\n",
    "        WITH (table_type='ICEBERG',\n",
    "        location='s3://sb-test-bucket-ireland/wo/de-usecases/athena/database/ICE_dummy_data_temp',\n",
    "        format='PARQUET',\n",
    "        is_external=false)\n",
    "    AS \n",
    "    WITH end_date AS (\n",
    "        SELECT product_id, extraction_timestamp, LEAD(extraction_timestamp, 1, TIMESTAMP '2250-01-01 00:00:00')\n",
    "            OVER (PARTITION BY product_id \n",
    "        ORDER BY extraction_timestamp) AS end_datetime_lead\n",
    "        FROM wto_hudi_iceberg.ICE_dummy_data\n",
    "    )\n",
    "    SELECT product_id, extraction_timestamp, end_datetime_lead,\n",
    "        CASE WHEN end_datetime_lead = CAST(TIMESTAMP '2250-01-01 00:00:00' AS TIMESTAMP(6)) THEN true\n",
    "            ELSE false END AS is_current \n",
    "    FROM end_date\n",
    "\"\"\"\n",
    "sql2_5 = \"\"\" SELECT ice.*, tmp.*\n",
    "    FROM wto_hudi_iceberg.ICE_dummy_data ice\n",
    "    JOIN wto_hudi_iceberg.ICE_dummy_data_temp tmp\n",
    "    ON (tmp.product_id = ice.product_id\n",
    "    AND tmp.extraction_timestamp = ice.extraction_timestamp)\"\"\"\n",
    "sql3 = \"\"\"MERGE INTO wto_hudi_iceberg.ICE_dummy_data ice\n",
    "    USING wto_hudi_iceberg.ICE_dummy_data_temp tmp\n",
    "    ON (tmp.product_id = ice.product_id\n",
    "    AND tmp.extraction_timestamp = ice.extraction_timestamp)\n",
    "    WHEN MATCHED \n",
    "        THEN UPDATE\n",
    "            SET ice.end_datetime = tmp.end_datetime_lead,\n",
    "                ice.is_current = tmp.is_current\"\"\"\n",
    "resp = wr.athena.start_query_execution(\n",
    "    sql=sql3, database=\"wto_hudi_iceberg\", workgroup='Athena3', wait=True\n",
    ")\n",
    "resp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Simple CDC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For live data return insert sql script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**SIMPLE INSERT**\n",
      "\n",
      "    INSERT INTO wto_hudi_iceberg.ICE_dummy_data\n",
      "        SELECT src.product_id, src.product_name, src.price, \n",
      "            CAST(src.extraction_timestamp AS TIMESTAMP(6)) AS extraction_timestamp, src.op,\n",
      "            CAST(src.extraction_timestamp AS TIMESTAMP(6)), NULL, NULL\n",
      "        FROM wto_hudi_iceberg.dummy_data_updates src\n",
      "\n",
      "\n",
      "**SIMPLE MERGE**\n",
      "\n",
      "    MERGE INTO wto_hudi_iceberg.ICE_dummy_data dest\n",
      "    USING wto_hudi_iceberg.dummy_data_updates src\n",
      "        ON src.product_id = dest.product_id\n",
      "    WHEN MATCHED AND dest.is_current = TRUE \n",
      "        THEN UPDATE\n",
      "            SET end_datetime = src.extraction_timestamp, is_current = FALSE\n",
      "    WHEN MATCHED AND dest.extraction_timestamp = dest.start_datetime\n",
      "        THEN UPDATE\n",
      "        SET end_datetime = CAST(TIMESTAMP '2250-01-01 00:00:00' AS TIMESTAMP(6))\n",
      "        , is_current = TRUE;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scd2_simple_sql_queries = af.scd2_simple(\n",
    "    ##NOTE:pandas example uses \"bulk_insert_filepath\" generated from previous query\n",
    "    full_load_filepath,\n",
    "    updates_filepath,\n",
    "    output_data_directory,\n",
    "    future_end_datetime,\n",
    "    primary_key,\n",
    "    demo=\"print_sql\"\n",
    ")\n",
    "print(scd2_simple_sql_queries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo data update demo iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed INSERT in 2472 milliseconds,  481 bytes scanned\n",
      "completed MERGE in 2472 milliseconds,  481 bytes scanned\n",
      "total MB scanned: 0.0009174346923828125 in 4.944 seconds, ~ Cost =  $4.374669515527785e-09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>extraction_timestamp</th>\n",
       "      <th>op</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>is_current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>Heater</td>\n",
       "      <td>250</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001</td>\n",
       "      <td>Heater</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>Thermostat</td>\n",
       "      <td>400</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002</td>\n",
       "      <td>Thermostat</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003</td>\n",
       "      <td>Television</td>\n",
       "      <td>600</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00003</td>\n",
       "      <td>Television</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00004</td>\n",
       "      <td>Blender</td>\n",
       "      <td>100</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00004</td>\n",
       "      <td>Blender</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005</td>\n",
       "      <td>USB charger</td>\n",
       "      <td>50</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>USB charger</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_name  price extraction_timestamp    op  \\\n",
       "0      00001       Heater    250  2022-01-01 01:01:01  <NA>   \n",
       "1      00001       Heater   1000  2023-01-01 01:01:01     U   \n",
       "2      00002   Thermostat    400  2022-01-01 01:01:01  <NA>   \n",
       "3      00002   Thermostat   1000  2023-01-01 01:01:01     U   \n",
       "4      00003   Television    600  2022-01-01 01:01:01  <NA>   \n",
       "5      00003   Television   1000  2023-01-01 01:01:01     U   \n",
       "6      00004      Blender    100  2022-01-01 01:01:01  <NA>   \n",
       "7      00004      Blender   1000  2023-01-01 01:01:01     U   \n",
       "8      00005  USB charger     50  2022-01-01 01:01:01  <NA>   \n",
       "9      00005  USB charger   1000  2023-01-01 01:01:01     U   \n",
       "\n",
       "       start_datetime        end_datetime  is_current  \n",
       "0 2022-01-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "1 2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "2 2022-01-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "3 2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "4 2022-01-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "5 2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "6 2022-01-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "7 2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "8 2022-01-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "9 2023-01-01 01:01:01 2250-01-01 00:00:00        True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scd2_simple_filepath = af.scd2_simple(\n",
    "    full_load_filepath, \n",
    "    updates_filepath,\n",
    "    output_data_directory, \n",
    "    future_end_datetime, \n",
    "    primary_key)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {dest_table_name} ORDER BY {primary_key}, extraction_timestamp\", database=db_name, ctas_approach=False, workgroup='Athena3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Complex CDC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For live data return sql script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        **SIMPLE INSERT**\n",
      "\n",
      "    INSERT INTO wto_hudi_iceberg.ICE_dummy_data\n",
      "        SELECT src.product_id, src.product_name, src.price, \n",
      "            CAST(src.extraction_timestamp AS TIMESTAMP(6)) AS extraction_timestamp, src.op,\n",
      "            CAST(src.extraction_timestamp AS TIMESTAMP(6)), NULL, NULL\n",
      "        FROM wto_hudi_iceberg.dummy_data_late_updates src\n",
      "\n",
      "        **COMPLEX TEMP TABLE**\n",
      "\n",
      "    CREATE TABLE IF NOT EXISTS wto_hudi_iceberg.ICE_dummy_data_temp\n",
      "        WITH (table_type='ICEBERG',\n",
      "        location='s3://sb-test-bucket-ireland/wo/de-usecases/athena/database/ICE_dummy_data_temp',\n",
      "        format='PARQUET',\n",
      "        is_external=false)\n",
      "    AS \n",
      "    WITH end_date AS (\n",
      "        SELECT product_id, extraction_timestamp, LEAD(extraction_timestamp, 1, TIMESTAMP '2250-01-01 00:00:00')\n",
      "            OVER (PARTITION BY product_id \n",
      "        ORDER BY extraction_timestamp) AS end_datetime_lead\n",
      "        FROM wto_hudi_iceberg.ICE_dummy_data\n",
      "    )\n",
      "    SELECT product_id, extraction_timestamp, end_datetime_lead,\n",
      "        CASE WHEN end_datetime_lead = CAST(TIMESTAMP '2250-01-01 00:00:00' AS TIMESTAMP(6)) THEN true\n",
      "            ELSE false END AS is_current \n",
      "    FROM end_date\n",
      "\n",
      "\n",
      "        **COMPLEX MERGE**\n",
      "\n",
      "    MERGE INTO wto_hudi_iceberg.ICE_dummy_data ice\n",
      "    USING wto_hudi_iceberg.ICE_dummy_data_temp tmp\n",
      "    ON (tmp.product_id = ice.product_id\n",
      "    AND tmp.extraction_timestamp = ice.extraction_timestamp)\n",
      "    WHEN MATCHED \n",
      "        THEN UPDATE\n",
      "            SET ice.end_datetime = tmp.end_datetime_lead,\n",
      "                ice.is_current = tmp.is_current\n",
      "\n",
      "        **COMPLEX DROP**\n",
      "\n",
      "    DROP TABLE IF EXISTS wto_hudi_iceberg.ICE_dummy_data_temp;\n",
      "\n",
      "        \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "scd2_complex = af.scd2_complex(\n",
    "    ##NOTE:pandas example uses \"bulk_insert_filepath\" generated from previous query\n",
    "    full_load_filepath,\n",
    "    late_updates_filepath,\n",
    "    output_data_directory,\n",
    "    future_end_datetime,\n",
    "    primary_key,\n",
    "    demo=\"print_sql\"\n",
    ")\n",
    "print(scd2_complex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo data run insert & merge to iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT CDC's ...\n",
      "Completed INSERT in 2793 milliseconds, scanned 481 bytes\n",
      "        CREATE TEMP TABLE ...\n",
      "Completed CREATE TEMP TABLE in 3701 milliseconds, scanned 306 bytes\n",
      "        MERGE UPDATES ...\n",
      "Completed MERGE in 6502 milliseconds, scanned 1311 bytes\n",
      "        DROP TEMP TABLE ...\n",
      "Completed DROP TEMP TABLE in 1132 milliseconds, scanned 0 bytes\n",
      "Total Scanned MB: 0.0020008087158203125 in 14.128 seconds, ~ Cost = $9.540599421598017e-09\n",
      "s3://sb-test-bucket-ireland/wo/de-usecases/athena/database/ICE_dummy_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>extraction_timestamp</th>\n",
       "      <th>op</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>is_current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002</td>\n",
       "      <td>Thermostat</td>\n",
       "      <td>400</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00003</td>\n",
       "      <td>Television</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004</td>\n",
       "      <td>Blender</td>\n",
       "      <td>100</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003</td>\n",
       "      <td>Television</td>\n",
       "      <td>600</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004</td>\n",
       "      <td>Blender</td>\n",
       "      <td>500</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004</td>\n",
       "      <td>Blender</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005</td>\n",
       "      <td>USB charger</td>\n",
       "      <td>50</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00001</td>\n",
       "      <td>Heater</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00001</td>\n",
       "      <td>Heater</td>\n",
       "      <td>500</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>USB charger</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00001</td>\n",
       "      <td>Heater</td>\n",
       "      <td>250</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2022-01-01 01:01:01</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00003</td>\n",
       "      <td>Television</td>\n",
       "      <td>500</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00005</td>\n",
       "      <td>USB charger</td>\n",
       "      <td>500</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00002</td>\n",
       "      <td>Thermostat</td>\n",
       "      <td>500</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2022-06-01 01:01:01</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00002</td>\n",
       "      <td>Thermostat</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>U</td>\n",
       "      <td>2023-01-01 01:01:01</td>\n",
       "      <td>2250-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id product_name  price extraction_timestamp    op  \\\n",
       "0       00002   Thermostat    400  2022-01-01 01:01:01  <NA>   \n",
       "1       00003   Television   1000  2023-01-01 01:01:01     U   \n",
       "2       00004      Blender    100  2022-01-01 01:01:01  <NA>   \n",
       "3       00003   Television    600  2022-01-01 01:01:01  <NA>   \n",
       "4       00004      Blender    500  2022-06-01 01:01:01     U   \n",
       "5       00004      Blender   1000  2023-01-01 01:01:01     U   \n",
       "6       00005  USB charger     50  2022-01-01 01:01:01  <NA>   \n",
       "7       00001       Heater   1000  2023-01-01 01:01:01     U   \n",
       "8       00001       Heater    500  2022-06-01 01:01:01     U   \n",
       "9       00005  USB charger   1000  2023-01-01 01:01:01     U   \n",
       "10      00001       Heater    250  2022-01-01 01:01:01  <NA>   \n",
       "11      00003   Television    500  2022-06-01 01:01:01     U   \n",
       "12      00005  USB charger    500  2022-06-01 01:01:01     U   \n",
       "13      00002   Thermostat    500  2022-06-01 01:01:01     U   \n",
       "14      00002   Thermostat   1000  2023-01-01 01:01:01     U   \n",
       "\n",
       "        start_datetime        end_datetime  is_current  \n",
       "0  2022-01-01 01:01:01 2022-06-01 01:01:01       False  \n",
       "1  2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "2  2022-01-01 01:01:01 2022-06-01 01:01:01       False  \n",
       "3  2022-01-01 01:01:01 2022-06-01 01:01:01       False  \n",
       "4  2022-06-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "5  2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "6  2022-01-01 01:01:01 2022-06-01 01:01:01       False  \n",
       "7  2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "8  2022-06-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "9  2023-01-01 01:01:01 2250-01-01 00:00:00        True  \n",
       "10 2022-01-01 01:01:01 2022-06-01 01:01:01       False  \n",
       "11 2022-06-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "12 2022-06-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "13 2022-06-01 01:01:01 2023-01-01 01:01:01       False  \n",
       "14 2023-01-01 01:01:01 2250-01-01 00:00:00        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scd2_complex = af.scd2_complex(\n",
    "    ##NOTE:pandas example uses \"bulk_insert_filepath\" generated from previous query\n",
    "    full_load_filepath,\n",
    "    late_updates_filepath,\n",
    "    output_data_directory,\n",
    "    future_end_datetime,\n",
    "    primary_key,\n",
    "    demo=\"demo\"\n",
    ")\n",
    "print(scd2_complex)\n",
    "wr.athena.read_sql_query(\"SELECT * FROM wto_hudi_iceberg.ICE_dummy_data\", database=db_name, ctas_approach=False, workgroup='Athena3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Total Glue Cost = $0.00019592222222222222\n",
      "~ Total Athena Cost = $1.6143530956469476e-08\n",
      "pandas on glue was 12136 times more expensive than athena, but 15 times faster\n"
     ]
    }
   ],
   "source": [
    "## Cost comparision\n",
    "glue_total_time_sec = 0.697 + 0.327 + 0.579\n",
    "glue_cost_per_hr = 0.44\n",
    "glue_total_cost = glue_total_time_sec * glue_cost_per_hr/60**2\n",
    "print(f\"~ Total Glue Cost = ${glue_total_cost}\")\n",
    "\n",
    "athena_total_time_sec = 4.702 + 4.944  + 14.128 \n",
    "athena_total_data_mb = 0.0004673004150390625 + 0.0009174346923828125 + 0.0020008087158203125\n",
    "athena_cost_per_tb = 5.00\n",
    "athena_total_cost = athena_total_data_mb * athena_cost_per_tb/1024**2\n",
    "print(f\"~ Total Athena Cost = ${athena_total_cost}\")\n",
    "print(f\"pandas on glue was {glue_total_cost/athena_total_cost:.0f} times more expensive than athena, but {athena_total_time_sec/glue_total_time_sec:.0f} times faster\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
