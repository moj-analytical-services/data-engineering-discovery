{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Insert and add curation columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_insert_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id product_name  price extraction_timestamp    op\n",
      "0      00001       Heater    250  2022-01-01 01:01:01  None\n",
      "1      00002   Thermostat    400  2022-01-01 01:01:01  None\n",
      "2      00003   Television    600  2022-01-01 01:01:01  None\n",
      "3      00004      Blender    100  2022-01-01 01:01:01  None\n",
      "4      00005  USB charger     50  2022-01-01 01:01:01  None\n"
     ]
    }
   ],
   "source": [
    "full_load = pd.read_parquet('../helpers/dummy_example_creator/full_load.parquet')\n",
    "print(full_load.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id product_name  price extraction_timestamp    op  \\\n",
      "0      00001       Heater    250  2022-01-01 01:01:01  None   \n",
      "1      00002   Thermostat    400  2022-01-01 01:01:01  None   \n",
      "2      00003   Television    600  2022-01-01 01:01:01  None   \n",
      "3      00004      Blender    100  2022-01-01 01:01:01  None   \n",
      "4      00005  USB charger     50  2022-01-01 01:01:01  None   \n",
      "\n",
      "       start_datetime end_datetime  is_current  \n",
      "0 2022-01-01 01:01:01   2250-01-01        True  \n",
      "1 2022-01-01 01:01:01   2250-01-01        True  \n",
      "2 2022-01-01 01:01:01   2250-01-01        True  \n",
      "3 2022-01-01 01:01:01   2250-01-01        True  \n",
      "4 2022-01-01 01:01:01   2250-01-01        True  \n"
     ]
    }
   ],
   "source": [
    "end_datetime = datetime.datetime(2250, 1, 1)\n",
    "\n",
    "full_load['start_datetime'] = full_load['extraction_timestamp']\n",
    "full_load['end_datetime'] = end_datetime\n",
    "full_load['is_current'] = True\n",
    "\n",
    "print(full_load.head())\n",
    "full_load.to_parquet('bulk_insert.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11295485496520996\n"
     ]
    }
   ],
   "source": [
    "bulk_insert_process_time = time.time() - bulk_insert_start_time\n",
    "print(bulk_insert_process_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slowly Changing Dimension Type 2\n",
    "\n",
    "The updates are created by replacing one column with the same value to simplify the testing.\n",
    "The soft deletes are not taken into account since very similar process from a performance perspective.\n",
    "\n",
    "1. Read updates\n",
    "2. Join full load with updates on primary key\n",
    "3. Set `end_datetime` to the `extraction_timestamp` of the updated records \n",
    "4. Close the existing records\n",
    "5. Add curation columms to updates\n",
    "6. Append updated data to existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd2_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id product_name  price extraction_timestamp op\n",
      "0      00001       Heater   1000           2023-01-01  U\n",
      "1      00002   Thermostat   1000           2023-01-01  U\n",
      "2      00003   Television   1000           2023-01-01  U\n",
      "3      00004      Blender   1000           2023-01-01  U\n",
      "4      00005  USB charger   1000           2023-01-01  U\n"
     ]
    }
   ],
   "source": [
    "updates= pd.read_parquet('../helpers/dummy_example_creator/updates.parquet')\n",
    "print(updates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id product_name  price extraction_timestamp    op  \\\n",
      "0      00001       Heater    250  2022-01-01 01:01:01  None   \n",
      "1      00002   Thermostat    400  2022-01-01 01:01:01  None   \n",
      "2      00003   Television    600  2022-01-01 01:01:01  None   \n",
      "3      00004      Blender    100  2022-01-01 01:01:01  None   \n",
      "4      00005  USB charger     50  2022-01-01 01:01:01  None   \n",
      "\n",
      "       start_datetime end_datetime  is_current  \n",
      "0 2022-01-01 01:01:01   2023-01-01       False  \n",
      "1 2022-01-01 01:01:01   2023-01-01       False  \n",
      "2 2022-01-01 01:01:01   2023-01-01       False  \n",
      "3 2022-01-01 01:01:01   2023-01-01       False  \n",
      "4 2022-01-01 01:01:01   2023-01-01       False  \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(full_load,\n",
    "              updates[['product_id','extraction_timestamp']],\n",
    "              on='product_id',\n",
    "              suffixes=(None, \"_y\")\n",
    "              )\n",
    "df['end_datetime'] = df['extraction_timestamp_y']\n",
    "df.drop(columns=['extraction_timestamp_y'],inplace=True)\n",
    "df['is_current'] = False\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id product_name  price extraction_timestamp    op  \\\n",
      "0      00001       Heater    250  2022-01-01 01:01:01  None   \n",
      "1      00002   Thermostat    400  2022-01-01 01:01:01  None   \n",
      "2      00003   Television    600  2022-01-01 01:01:01  None   \n",
      "3      00004      Blender    100  2022-01-01 01:01:01  None   \n",
      "4      00005  USB charger     50  2022-01-01 01:01:01  None   \n",
      "5      00001       Heater   1000  2023-01-01 00:00:00     U   \n",
      "6      00002   Thermostat   1000  2023-01-01 00:00:00     U   \n",
      "7      00003   Television   1000  2023-01-01 00:00:00     U   \n",
      "8      00004      Blender   1000  2023-01-01 00:00:00     U   \n",
      "9      00005  USB charger   1000  2023-01-01 00:00:00     U   \n",
      "\n",
      "       start_datetime end_datetime  is_current  \n",
      "0 2022-01-01 01:01:01   2023-01-01       False  \n",
      "1 2022-01-01 01:01:01   2023-01-01       False  \n",
      "2 2022-01-01 01:01:01   2023-01-01       False  \n",
      "3 2022-01-01 01:01:01   2023-01-01       False  \n",
      "4 2022-01-01 01:01:01   2023-01-01       False  \n",
      "5 2023-01-01 00:00:00   2250-01-01        True  \n",
      "6 2023-01-01 00:00:00   2250-01-01        True  \n",
      "7 2023-01-01 00:00:00   2250-01-01        True  \n",
      "8 2023-01-01 00:00:00   2250-01-01        True  \n",
      "9 2023-01-01 00:00:00   2250-01-01        True  \n"
     ]
    }
   ],
   "source": [
    "updates['start_datetime'] = updates['extraction_timestamp']\n",
    "updates['end_datetime'] = end_datetime\n",
    "updates['is_current'] = True\n",
    "\n",
    "output = pd.concat([df,updates],ignore_index=True)\n",
    "print(output.head(10))\n",
    "output.to_parquet('updated_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12783598899841309\n"
     ]
    }
   ],
   "source": [
    "scd2_process_time = time.time() - scd2_start_time\n",
    "print(scd2_process_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dedupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute deleted records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
